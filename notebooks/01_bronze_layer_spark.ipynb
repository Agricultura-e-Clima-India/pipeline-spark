{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ff749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9f17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from spark_jobs.spark_session_manager import get_spark_session\n",
    "from spark_jobs.config import BRONZE_PATH, ensure_data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125bcc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_kaggle_csv(spark, handle: str, csv_name: str | None = None):\n",
    "    '''Download a Kaggle dataset with kagglehub and load a CSV as a Spark DataFrame.'''\n",
    "    dataset_dir = Path(kagglehub.dataset_download(handle))\n",
    "    candidates = []\n",
    "\n",
    "    if csv_name:\n",
    "        target = Path(csv_name)\n",
    "        candidates.extend(\n",
    "            [\n",
    "                dataset_dir / target,\n",
    "                dataset_dir / target.name,\n",
    "                dataset_dir / 'data' / target.name,\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        candidates.extend(list(dataset_dir.glob('*.csv')))\n",
    "        data_dir = dataset_dir / 'data'\n",
    "        if data_dir.exists():\n",
    "            candidates.extend(list(data_dir.glob('*.csv')))\n",
    "\n",
    "    csv_path = next((path for path in candidates if path.exists()), None)\n",
    "    if csv_path is None:\n",
    "        print(f'No CSV found for {handle}')\n",
    "        return None\n",
    "\n",
    "    print(f'Reading {csv_path.name} from {csv_path.parent}')\n",
    "    return (\n",
    "        spark.read.option('header', True)\n",
    "        .option('inferSchema', True)\n",
    "        .option('mode', 'DROPMALFORMED')\n",
    "        .csv(str(csv_path))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d678daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/nikhilmahajan29/crop-production-statistics-india?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.29M/3.29M [00:02<00:00, 1.62MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading APY.csv from /home/jovyan/.cache/kagglehub/datasets/nikhilmahajan29/crop-production-statistics-india/versions/3\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/swarooprangle/indian-agriculture-and-climate-dataset-1961-2018?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90.7k/90.7k [00:00<00:00, 684kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Reading rainfall.csv from /home/jovyan/.cache/kagglehub/datasets/swarooprangle/indian-agriculture-and-climate-dataset-1961-2018/versions/1/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading temperature.csv from /home/jovyan/.cache/kagglehub/datasets/swarooprangle/indian-agriculture-and-climate-dataset-1961-2018/versions/1/data\n"
     ]
    }
   ],
   "source": [
    "ensure_data_dirs()\n",
    "spark = get_spark_session('Bronze Layer')\n",
    "\n",
    "df_stats = load_kaggle_csv(spark, 'nikhilmahajan29/crop-production-statistics-india')\n",
    "df_rain = load_kaggle_csv(\n",
    "    spark,\n",
    "    'swarooprangle/indian-agriculture-and-climate-dataset-1961-2018',\n",
    "    'data/rainfall.csv',\n",
    ")\n",
    "df_temp = load_kaggle_csv(\n",
    "    spark,\n",
    "    'swarooprangle/indian-agriculture-and-climate-dataset-1961-2018',\n",
    "    'data/temperature.csv',\n",
    ")\n",
    "\n",
    "if any(df is None for df in (df_stats, df_rain, df_temp)):\n",
    "    raise RuntimeError('Missing source datasets for bronze step.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34c60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_climate = {\n",
    "    'JAN-FEB': 'TEMP_JAN_FEB',\n",
    "    'MAR-MAY': 'TEMP_MAR_MAY',\n",
    "    'JUN-SEP': 'TEMP_JUN_SEP',\n",
    "    'OCT-DEC': 'TEMP_OCT_DEC',\n",
    "    'ANNUAL': 'TEMP_ANNUAL',\n",
    "}\n",
    "\n",
    "# Normalize YEAR column across sources\n",
    "for candidate in ['YEAR', 'Year', 'year']:\n",
    "    if candidate in df_stats.columns and candidate != 'YEAR':\n",
    "        df_stats = df_stats.withColumnRenamed(candidate, 'YEAR')\n",
    "    if candidate in df_rain.columns and candidate != 'YEAR':\n",
    "        df_rain = df_rain.withColumnRenamed(candidate, 'YEAR')\n",
    "    if candidate in df_temp.columns and candidate != 'YEAR':\n",
    "        df_temp = df_temp.withColumnRenamed(candidate, 'YEAR')\n",
    "\n",
    "if 'Area ' in df_stats.columns:\n",
    "    df_stats = df_stats.withColumnRenamed('Area ', 'Area')\n",
    "if 'Crop_Year' in df_stats.columns and 'YEAR' not in df_stats.columns:\n",
    "    df_stats = df_stats.withColumnRenamed('Crop_Year', 'YEAR')\n",
    "\n",
    "if 'YEAR' not in df_stats.columns or 'YEAR' not in df_rain.columns or 'YEAR' not in df_temp.columns:\n",
    "    raise RuntimeError('Column YEAR not found in one of the source datasets after rename.')\n",
    "\n",
    "# Rename temperature columns before the join to avoid name collisions\n",
    "upper_to_original = {col_name.upper(): col_name for col_name in df_temp.columns}\n",
    "df_temp_clean = df_temp\n",
    "for old_upper, new_name in rename_climate.items():\n",
    "    if old_upper in upper_to_original:\n",
    "        df_temp_clean = df_temp_clean.withColumnRenamed(upper_to_original[old_upper], new_name)\n",
    "\n",
    "df_climate = df_rain.join(df_temp_clean, on=['YEAR'], how='inner')\n",
    "df_combined = df_stats.join(df_climate, on=['YEAR'], how='inner')\n",
    "\n",
    "df_bronze = df_combined.withColumn('data_ingestao', F.current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb8ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze saved to /home/jovyan/work/data/bronze/dados_brutos.parquet\n",
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- District : string (nullable = true)\n",
      " |-- Crop: string (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- Area: double (nullable = true)\n",
      " |-- Production: integer (nullable = true)\n",
      " |-- Yield: double (nullable = true)\n",
      " |-- JAN: double (nullable = true)\n",
      " |-- FEB: double (nullable = true)\n",
      " |-- MAR: double (nullable = true)\n",
      " |-- APR: double (nullable = true)\n",
      " |-- MAY: double (nullable = true)\n",
      " |-- JUN: double (nullable = true)\n",
      " |-- JUL: double (nullable = true)\n",
      " |-- AUG: double (nullable = true)\n",
      " |-- SEP: double (nullable = true)\n",
      " |-- OCT: double (nullable = true)\n",
      " |-- NOV: double (nullable = true)\n",
      " |-- DEC: double (nullable = true)\n",
      " |-- ANN: double (nullable = true)\n",
      " |-- Jan-Feb: double (nullable = true)\n",
      " |-- Mar-May: double (nullable = true)\n",
      " |-- Jun-Sep: double (nullable = true)\n",
      " |-- Oct-Dec: double (nullable = true)\n",
      " |-- TEMP_ANNUAL: double (nullable = true)\n",
      " |-- TEMP_JAN_FEB: double (nullable = true)\n",
      " |-- TEMP_MAR_MAY: double (nullable = true)\n",
      " |-- TEMP_JUN_SEP: double (nullable = true)\n",
      " |-- TEMP_OCT_DEC: double (nullable = true)\n",
      " |-- data_ingestao: timestamp (nullable = false)\n",
      "\n",
      "+----+--------------------+--------------+--------+-----------+------+----------+-----+----+----+----+----+----+-----+-----+-----+-----+-----+----+----+------+-------+-------+-------+-------+-----------+------------+------------+------------+------------+--------------------+\n",
      "|YEAR|               State|     District |    Crop|     Season|  Area|Production|Yield| JAN| FEB| MAR| APR| MAY|  JUN|  JUL|  AUG|  SEP|  OCT| NOV| DEC|   ANN|Jan-Feb|Mar-May|Jun-Sep|Oct-Dec|TEMP_ANNUAL|TEMP_JAN_FEB|TEMP_MAR_MAY|TEMP_JUN_SEP|TEMP_OCT_DEC|       data_ingestao|\n",
      "+----+--------------------+--------------+--------+-----------+------+----------+-----+----+----+----+----+----+-----+-----+-----+-----+-----+----+----+------+-------+-------+-------+-------+-----------+------------+------------+------------+------------+--------------------+\n",
      "|2009|Andaman and Nicob...|      NICOBARS|Arecanut|Autumn     |4153.0|      3120| 0.75|12.0|12.0|14.2|25.1|56.0| 85.7|280.7|192.5|139.4| 71.4|53.7|11.1| 953.7|   24.0|   95.3|  698.3|  136.1|      25.11|       20.72|       26.86|       27.89|       22.58|2025-11-27 04:27:...|\n",
      "|2009|Andaman and Nicob...|      NICOBARS|Arecanut|Summer     |4153.0|      2080|  0.5|12.0|12.0|14.2|25.1|56.0| 85.7|280.7|192.5|139.4| 71.4|53.7|11.1| 953.7|   24.0|   95.3|  698.3|  136.1|      25.11|       20.72|       26.86|       27.89|       22.58|2025-11-27 04:27:...|\n",
      "|2003|Andaman and Nicob...|      NICOBARS|Arecanut|Whole Year |1261.0|      1525| 1.21| 7.6|45.6|33.3|35.4|39.1|184.5|316.7|255.3|191.4|100.6|15.5|18.6|1243.6|   53.2|  107.8|  947.9|  134.8|      24.72|       19.82|       26.52|       27.64|       22.23|2025-11-27 04:27:...|\n",
      "|2004|Andaman and Nicob...|      NICOBARS|Arecanut|Whole Year |1264.7|       806| 0.64|25.7| 8.8|11.4|59.0|88.9|158.7|242.1|248.7|124.6| 92.2|15.8| 4.6|1080.5|   34.5|  159.2|  774.1|  112.6|      24.74|       19.93|       27.06|       27.33|       22.24|2025-11-27 04:27:...|\n",
      "|2003|Andaman and Nicob...|SOUTH ANDAMANS|Arecanut|Whole Year |3118.0|      5182| 1.66| 7.6|45.6|33.3|35.4|39.1|184.5|316.7|255.3|191.4|100.6|15.5|18.6|1243.6|   53.2|  107.8|  947.9|  134.8|      24.72|       19.82|       26.52|       27.64|       22.23|2025-11-27 04:27:...|\n",
      "+----+--------------------+--------------+--------+-----------+------+----------+-----+----+----+----+----+----+-----+-----+-----+-----+-----+----+----+------+-------+-------+-------+-------+-----------+------------+------------+------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bronze.write.mode('overwrite').parquet(str(BRONZE_PATH))\n",
    "print(f'Bronze saved to {BRONZE_PATH}')\n",
    "df_bronze.printSchema()\n",
    "df_bronze.show(5)\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
